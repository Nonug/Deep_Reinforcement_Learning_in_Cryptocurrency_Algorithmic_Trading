# Deep Reinforcement Learning in Cryptocurrency Algorithmic Trading


## Getting Started
### Prerequisites
numpy<br/>
pandas<br/>
Matplotlib<br/>
gym<br/>
tqdm<br/>
tabulate<br/>
torch<br/>
etherscan<br/>

## Usage
1. Run the jupyter notebooks in different `tdqn` to construct tdqn models in different versions

## This version
* action space = 2
* default state = ['Close',"Low","High","Volume","s2f"]
* network = {"DQN", "LSTM", "BiLSTM", "DuelingDQN"}
* cross validation is implemented
* different folders for reducing state space

## todos
* ConvDuelingDQN 
* reducing state space by sequential backward selection, and record the results in `useful_results`
* regularisation, dropout layer, early stopping
* continuous action space
* modify Sharpe ratio reward
* optimization

## problems
* I think ConvDuelingDQN takes a matrix with specific shape as input, but our input is not in that shape
* An old problem, idk why the results generated by me are poorer, my basic dqn model go bust in the testing set. And the rendering graphs do not have long short symbols. The results are shown in useful_results.
* low and high are removed together because the normalization of low uses the state high. Because of similar reason, close price can hardly be removed.

## Authors
* [leehiulong](https://github.com/leehiulong)
* [e](https://github.com/Nonug)
* [johnnycls](https://github.com/johnnycls)

## Acknowledgements
* [glassnode](https://glassnode.com/)
* [tdqn](https://github.com/ThibautTheate/An-Application-of-Deep-Reinforcement-Learning-to-Algorithmic-Trading)
* [Cryptocurrency Time Series by GuangZhiXie](https://github.com/guangzhixie/cryptocurrency-time-series)